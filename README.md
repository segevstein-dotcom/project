# SOLE LayerNorm Implementation

**Hardware-Software Co-design of LayerNorm for Efficient Transformer Inference**

This project implements Stage 1 (statistics calculation) of the SOLE (Software-Hardware Co-design of Softmax and LayerNorm) algorithm in C, optimized for hardware acceleration.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Algorithm Overview](#algorithm-overview)
- [Validation](#validation)
- [Results](#results)
- [Documentation](#documentation)

---

## ğŸ¯ Overview

SOLE is a hardware-software co-design approach for efficient LayerNorm and Softmax operations in Transformer models. This implementation focuses on:

- **8-bit Quantization** with PTF (Power-of-Two Factor) per-channel scaling
- **Dynamic Range Compression** (8-bit â†’ 4-bit) for hardware efficiency
- **Square Lookup Table** (16 entries) for fast variance computation
- **Fixed-point Arithmetic** optimized for hardware implementation

### What This Project Does

1. **Generates quantized data** from DeiT-small Transformer model
2. **Implements SOLE Stage 1** in C (mean and variance calculation)
3. **Validates results** against ground truth with comprehensive error analysis
4. **Isolates error sources** (quantization vs algorithm approximations)

---

## âœ¨ Features

- âœ… **PTF Sequential Quantization** - Per-channel alpha factors for optimal bit utilization
- âœ… **Hardware-Optimized Arithmetic** - Dynamic compression + Square LUT
- âœ… **Comprehensive Validation** - Multiple validation approaches
- âœ… **Detailed Tracing** - Debug individual vectors step-by-step
- âœ… **Well-Organized Structure** - Clean separation of concerns

---

## ğŸ“ Project Structure

```
implementation/
â”‚
â”œâ”€â”€ README.md                    # This file - Project overview
â”‚
â”œâ”€â”€ src/                         # C Implementation
â”‚   â”œâ”€â”€ main.c                   # SOLE Stage 1 implementation
â”‚   â”œâ”€â”€ utils.c                  # Data loading utilities
â”‚   â”œâ”€â”€ def.h                    # Constants and definitions
â”‚   â”œâ”€â”€ utils.h                  # Function headers
â”‚   â”œâ”€â”€ build.bat                # Windows build script
â”‚   â”œâ”€â”€ Makefile                 # Linux/Mac build
â”‚   â””â”€â”€ layernorm_test.exe       # Compiled binary
â”‚
â”œâ”€â”€ scripts/                     # Data Generation
â”‚   â”œâ”€â”€ README.md                # Scripts documentation
â”‚   â””â”€â”€ collect_real_data.py     # Generate quantized data from DeiT model
â”‚
â”œâ”€â”€ validation/                  # Validation & Analysis
â”‚   â”œâ”€â”€ README.md                # Validation documentation
â”‚   â”œâ”€â”€ validate_statistics.py   # Main validation (total error)
â”‚   â”œâ”€â”€ compare_c_vs_dequantized.py  # Algorithm error only
â”‚   â”œâ”€â”€ trace_vector.py          # Debug individual vectors
â”‚   â”œâ”€â”€ validation_report.txt    # Total error report
â”‚   â””â”€â”€ dequantized_comparison.txt   # Algorithm error report
â”‚
â”œâ”€â”€ experiments/                 # Historical Experiments
â”‚   â””â”€â”€ quantization/            # Quantization experiments archive
â”‚
â””â”€â”€ data/                        # Generated Data
    â””â”€â”€ quantized/
        â”œâ”€â”€ raw_input_vectors/   # Original float32 values (ground truth)
        â”œâ”€â”€ quantized_vectors/   # PTF-quantized uint8 values (vector_XXX.txt)
        â”œâ”€â”€ alpha_factors.txt    # Per-channel scaling factors
        â”œâ”€â”€ global_params.txt    # Global S, ZP, dimensions
        â”œâ”€â”€ layernorm_weights.txt    # Gamma & Beta (float)
        â”œâ”€â”€ gamma_quantized.txt  # Quantized gamma weights
        â”œâ”€â”€ beta_quantized.txt   # Quantized beta weights
        â”œâ”€â”€ golden_ref_vec000.txt    # Reference output
        â””â”€â”€ final_report.txt     # C implementation results
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** with packages: `torch`, `transformers`, `numpy`, `PIL`
- **C Compiler**: GCC (Linux/Mac) or MinGW (Windows)
- **Git** (optional, for version control)

### Step-by-Step Workflow

#### 1. Generate Quantized Data

```bash
# From implementation/ directory
python scripts/collect_real_data.py
```

**What it does:**
- Loads DeiT-small Transformer model
- Extracts LayerNorm input vectors (384 channels Ã— 197 vectors)
- Performs PTF quantization with global S/ZP and per-channel alpha
- Generates all data files in `data/quantized/`

#### 2. Compile and Run C Implementation

```bash
# Windows
cd src
build.bat
./layernorm_test.exe
cd ..

# Linux/Mac
cd src
make
./layernorm_test
cd ..
```

**What it does:**
- Loads quantized vectors and parameters
- Computes mean and variance using SOLE algorithm
- Applies dynamic compression (8â†’4 bit)
- Uses square LUT for variance calculation
- Saves results to `data/quantized/final_report.txt`

#### 3. Validate Results

```bash
# Main validation (quantization + algorithm error)
python validation/validate_statistics.py

# Algorithm-only validation (isolates algorithm error)
python validation/compare_c_vs_dequantized.py

# Debug specific vector (optional)
python validation/trace_vector.py 0
```

---

## ğŸ§® Algorithm Overview

### SOLE Stage 1: Statistics Calculation

**Goal:** Compute mean (Î¼) and variance (ÏƒÂ²) efficiently in hardware.

```
Input:  Quantized vector X_q [0-255], alpha factors Î±, global S, ZP
Output: Mean Î¼, Variance ÏƒÂ² (in real domain)
```

### Pipeline Stages

#### 1. **Centering** (Remove Zero Point)
```
X_centered = X_q - ZP
```
- Converts unsigned [0,255] to signed [-128,127]

#### 2. **Dynamic Compression** (8-bit â†’ 4-bit)
```
min_alpha = min(Î±)
X_compressed = compress(X_centered, min_alpha)
```
- Shift all values by min_alpha
- Dynamic range reduction for hardware efficiency
- Preserves relative relationships between channels

#### 3. **Accumulation** (Fixed-point)
```
Ex  = Î£ X_compressed[i]                    # Sum
Ex2 = Î£ square_lut[X_compressed[i]]        # Sum of squares
```
- **Square LUT**: 16-entry lookup table [-8,7] for fast squaring
- Accumulates in fixed-point (hardware-friendly)

#### 4. **Statistics Computation** (HW Domain)
```
mean_hw = Ex / N
var_hw  = (Ex2 / N) - mean_hwÂ²
```

#### 5. **Scale to Real Domain**
```
full_scale = 2^min_alpha Ã— S
mean_real  = mean_hw Ã— full_scale
var_real   = var_hw Ã— full_scaleÂ²        # Var(aX) = aÂ²Var(X)
```

### Quantization: PTF (Power-of-Two Factor)

**Sequential Quantization (SOLE Paper Convention):**

```python
# Step 1: Normalize to [-127, +127]
S = max(|X_real|) / 127
X_norm = X_real / S

# Step 2: Stretch underutilized channels (Î± â‰¤ 0)
X_stretched = X_norm / 2^Î±    # When Î± < 0, this multiplies (stretching)

# Step 3: Shift to [0, 255]
X_int = X_stretched + ZP      # ZP = 128
```

**Per-Channel Alpha Factors:**
- Channels with low utilization get negative Î± (e.g., Î±=-2)
- This stretches them to use more bits
- Channels using full range get Î±=0

---

## âœ… Validation

### Two Validation Approaches

#### 1. **Total Error** (`validate_statistics.py`)
- **Compares:** C implementation vs original raw float inputs
- **Shows:** Quantization error + Algorithm error (combined)
- **Use for:** Overall system validation

**Current Results:**
```
Mean Error:     7.33%  (average)
Variance Error: 10.40% (average)
Std Error:      5.36%  (average)
```

**Error Sources:**
1. Quantization loss (float32 â†’ uint8 â†’ float32)
2. Dynamic compression (8-bit â†’ 4-bit)
3. Square LUT approximation (16 entries)
4. Fixed-point arithmetic

#### 2. **Algorithm Error Only** (`compare_c_vs_dequantized.py`)
- **Compares:** C implementation vs dequantized quantized values
- **Shows:** Algorithm error only (excludes quantization)
- **Use for:** Understanding algorithm approximations

**Current Results:**
```
Mean Error:     0.004%  (essentially perfect!)
Variance Error: 10.20%  (from compression + LUT)
Std Error:      5.24%   (from compression + LUT)
```

**Key Finding:**
- Mean calculation has **NO algorithm error**
- All mean error comes from quantization, not the algorithm
- Variance/std errors are from dynamic compression and square LUT

---

## ğŸ“Š Results Summary

| Metric | Total Error | Algorithm Error |
|--------|-------------|-----------------|
| **Mean** | 7.33% | **0.004%** âœ¨ |
| **Variance** | 10.40% | 10.20% |
| **Std Dev** | 5.36% | 5.24% |

### Insights

âœ… **Mean calculation is perfect** - Algorithm introduces near-zero error
âœ… **Quantization dominates mean error** - 7.33% total, 0.004% algorithm
âœ… **Variance error is algorithmic** - Dynamic compression + Square LUT
âœ… **Acceptable trade-off** - ~10% variance error for significant hardware savings

---

## ğŸ“š Documentation

Each folder contains detailed documentation:

- **[scripts/README.md](scripts/README.md)** - Data generation scripts
- **[validation/README.md](validation/README.md)** - Validation methodology and tools
- **[experiments/quantization/README.md](experiments/quantization/README.md)** - Historical experiments

---

## ğŸ”§ Development

### Building from Source

**Windows (MinGW):**
```bash
cd src
gcc -o layernorm_test.exe main.c utils.c -lm -Wall
```

**Linux/Mac:**
```bash
cd src
gcc -o layernorm_test main.c utils.c -lm -Wall
# or
make
```

### Adding New Tests

1. Generate new data: `python scripts/collect_real_data.py`
2. Run C implementation: `cd src && ./layernorm_test.exe && cd ..`
3. Validate: `python validation/validate_statistics.py`

---

## ğŸ“– References

- **SOLE Paper:** "Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference"
- **Model:** DeiT-small (facebook/deit-small-patch16-224)
- **Quantization:** 8-bit symmetric with PTF per-channel scaling

---

## ğŸ“ License

This is an academic project for educational purposes.

---

## ğŸ‘¥ Contributors

- **Segev** - Implementation and validation
- **Claude Sonnet 4.5** - Code assistance and documentation

---

## ğŸ“ Academic Context

Part of Electrical Engineering Semester 7 project
Hebrew: ×¤×¨×•×™×™×§×˜ - ×¡××¡×˜×¨ ×–', ×”× ×“×¡×ª ×—×©××œ

---

**Last Updated:** January 2026
